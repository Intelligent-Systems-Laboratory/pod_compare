{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlimited-rolling",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trying-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "# Detectron imports\n",
    "from detectron2.engine import launch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.data import build_detection_test_loader, MetadataCatalog\n",
    "\n",
    "# Project imports\n",
    "import core.datasets.metadata as metadata\n",
    "\n",
    "from core.setup import setup_config, setup_arg_parser\n",
    "from offline_evaluation import compute_average_precision, compute_probabilistic_metrics, compute_calibration_errors\n",
    "from probabilistic_inference.probabilistic_inference import build_predictor\n",
    "from probabilistic_inference.inference_utils import instances_to_json\n",
    "\n",
    "from train_utils import ActiveTrainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "willing-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml', dataset_dir='/public-dataset/BDD/bdd100k', dist_url='tcp://127.0.0.1:50162', eval_only=False, inference_config='/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml', iou_correct=0.7, iou_min=0.1, machine_rank=0, min_allowed_score=0.0, num_gpus=1, num_machines=1, opts=[], random_seed=1000, resume=False, test_dataset='bdd_val')\n"
     ]
    }
   ],
   "source": [
    "##setup inference args, this also contains all the training args\n",
    "arg_parser = setup_arg_parser()\n",
    "args = arg_parser.parse_args(\"\")\n",
    "# Support single gpu inference only.\n",
    "args.num_gpus = 1\n",
    "args.dataset_dir = '/public-dataset/BDD/bdd100k'\n",
    "args.test_dataset = 'bdd_val'\n",
    "args.config_file = '/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml'\n",
    "args.inference_config = '/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml'\n",
    "args.random_seed = 1000\n",
    "args.resume=False\n",
    "print(\"Command Line Args:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authentic-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/../../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "Config '/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]\n",
      "numpy                   1.19.5\n",
      "detectron2              0.3 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.2\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.7.1 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.1.0\n",
      "torchvision             0.8.2 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\n",
      "fvcore                  0.1.3.post20210220\n",
      "cv2                     4.5.1\n",
      "----------------------  ----------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml', dataset_dir='/public-dataset/BDD/bdd100k', dist_url='tcp://127.0.0.1:50162', eval_only=False, inference_config='/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml', iou_correct=0.7, iou_min=0.1, machine_rank=0, min_allowed_score=0.0, num_gpus=1, num_machines=1, opts=[], random_seed=1000, resume=False, test_dataset='bdd_val')\n",
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mContents of args.config_file=/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml:\n",
      "_BASE_: \"Base-BDD-RetinaNet.yaml\"\n",
      "\n",
      "MODEL:\n",
      "    PROBABILISTIC_MODELING:\n",
      "        DROPOUT_RATE: 0.2 # 0.0 for no dropout\n",
      "\n",
      "        # One of the following Loss types: loss_attenuation'.\n",
      "        CLS_VAR_LOSS:\n",
      "            NAME: 'loss_attenuation'\n",
      "            NUM_SAMPLES: 10\n",
      "\n",
      "        # One of the following Loss types: 'none' or 'negative_log_likelihood', 'second_moment_matching', 'energy_loss'.\n",
      "        BBOX_COV_LOSS:\n",
      "            NAME: 'negative_log_likelihood'\n",
      "            COVARIANCE_TYPE: 'diagonal' # One of the following: 'full', 'diagonal' # Settings for dropout\n",
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mRunning with full config:\n",
      "ACTIVE_LEARNING:\n",
      "  DET_CLS_MERGE_MODE: mean\n",
      "  DET_CLS_SCORE: max_conf\n",
      "  EPOCH: 2\n",
      "  MAX_STEP: 1000\n",
      "  OUT_DIR: outputs/unsorted\n",
      "  START_N: 10000\n",
      "  STEP_N: 10000\n",
      "  W_CLS_SCORE: 0.5\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 8\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('bdd_val',)\n",
      "  TRAIN: ('bdd_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (720,)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: ProbabilisticRetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROBABILISTIC_MODELING:\n",
      "    ANNEALING_STEP: 0\n",
      "    BBOX_COV_LOSS:\n",
      "      COVARIANCE_TYPE: diagonal\n",
      "      NAME: negative_log_likelihood\n",
      "      NUM_SAMPLES: 1000\n",
      "    CLS_VAR_LOSS:\n",
      "      NAME: loss_attenuation\n",
      "      NUM_SAMPLES: 10\n",
      "    DROPOUT_RATE: 0.2\n",
      "    MC_DROPOUT:\n",
      "      \n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 7\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    DROPOUT_RATE: 0.2\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "OUTPUT_DIR: /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_1000\n",
      "PROBABILISTIC_INFERENCE:\n",
      "  AFFINITY_THRESHOLD: 0.9\n",
      "  BAYES_OD:\n",
      "    BOX_MERGE_MODE: bayesian_inference\n",
      "    CLS_MERGE_MODE: max_score\n",
      "    DIRCH_PRIOR: uniform\n",
      "  ENSEMBLES:\n",
      "    BOX_MERGE_MODE: pre_nms\n",
      "    RANDOM_SEED_NUMS: [0, 1000, 2000, 3000, 4000]\n",
      "  ENSEMBLES_DROPOUT:\n",
      "    BOX_MERGE_MODE: pre_nms\n",
      "  INFERENCE_MODE: bayes_od\n",
      "  MC_DROPOUT:\n",
      "    ENABLE: True\n",
      "    NUM_RUNS: 10\n",
      "SEED: 1000\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.0025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 30000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 4\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 90000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/24 12:33:04 detectron2]: \u001b[0mFull config saved to /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_1000/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# run this once per session only\n",
    "cfg = setup_config(args, random_seed=args.random_seed, is_testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cutting-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/24 12:33:08 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/richard.tanai/cvpr2/pod_compare/data_backup/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_0/model_final.pth\n",
      "\u001b[32m[02/24 12:33:13 d2.data.datasets.coco]: \u001b[0mLoading /public-dataset/BDD/bdd100k/labels/train_coco_format.json takes 4.49 seconds.\n",
      "\u001b[32m[02/24 12:33:13 d2.data.datasets.coco]: \u001b[0mLoaded 69863 images in COCO format from /public-dataset/BDD/bdd100k/labels/train_coco_format.json\n",
      "\u001b[32m[02/24 12:33:16 d2.data.build]: \u001b[0mRemoved 458 images with no usable annotations. 69405 images left.\n",
      "\u001b[32m[02/24 12:33:17 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    car     | 713211       |    bus     | 11672        |   truck    | 29971        |\n",
      "|   person   | 91349        |   rider    | 4517         |    bike    | 7210         |\n",
      "|   motor    | 3002         |            |              |            |              |\n",
      "|   total    | 860932       |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/24 12:33:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(720,), max_size=1333, sample_style='choice'), RandomFlip()]\n"
     ]
    }
   ],
   "source": [
    "#cfg = setup_config(args, random_seed=args.random_seed, is_testing=True)\n",
    "\n",
    "# Make sure only 1 data point is processed at a time. This simulates\n",
    "# deployment.\n",
    "cfg.defrost()\n",
    "cfg.DATALOADER.NUM_WORKERS = 32\n",
    "#cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "\n",
    "cfg.MODEL.DEVICE = device.type\n",
    "\n",
    "# Set up number of cpu threads\n",
    "torch.set_num_threads(cfg.DATALOADER.NUM_WORKERS)\n",
    "\n",
    "# Create inference output directory and copy inference config file to keep\n",
    "# track of experimental settings\n",
    "inference_output_dir = os.path.join(\n",
    "    cfg['OUTPUT_DIR'],\n",
    "    'inference',\n",
    "    args.test_dataset,\n",
    "    os.path.split(args.inference_config)[-1][:-5])\n",
    "os.makedirs(inference_output_dir, exist_ok=True)\n",
    "copyfile(args.inference_config, os.path.join(\n",
    "    inference_output_dir, os.path.split(args.inference_config)[-1]))\n",
    "\n",
    "# Get category mapping dictionary:\n",
    "train_thing_dataset_id_to_contiguous_id = MetadataCatalog.get(\n",
    "    cfg.DATASETS.TRAIN[0]).thing_dataset_id_to_contiguous_id\n",
    "test_thing_dataset_id_to_contiguous_id = MetadataCatalog.get(\n",
    "    args.test_dataset).thing_dataset_id_to_contiguous_id\n",
    "\n",
    "# If both dicts are equal or if we are performing out of distribution\n",
    "# detection, just flip the test dict.\n",
    "if (train_thing_dataset_id_to_contiguous_id == test_thing_dataset_id_to_contiguous_id) or (\n",
    "        cfg.DATASETS.TRAIN[0] == 'coco_not_in_voc_2017_train'):\n",
    "    cat_mapping_dict = dict(\n",
    "        (v, k) for k, v in test_thing_dataset_id_to_contiguous_id.items())\n",
    "else:\n",
    "    # If not equal, two situations: 1) BDD to KITTI and 2) COCO to PASCAL\n",
    "    cat_mapping_dict = dict(\n",
    "        (v, k) for k, v in test_thing_dataset_id_to_contiguous_id.items())\n",
    "    if 'voc' in args.test_dataset and 'coco' in cfg.DATASETS.TRAIN[0]:\n",
    "        dataset_mapping_dict = dict(\n",
    "            (v, k) for k, v in metadata.COCO_TO_VOC_CONTIGUOUS_ID.items())\n",
    "    elif 'kitti' in args.test_dataset and 'bdd' in cfg.DATASETS.TRAIN[0]:\n",
    "        dataset_mapping_dict = dict(\n",
    "            (v, k) for k, v in metadata.BDD_TO_KITTI_CONTIGUOUS_ID.items())\n",
    "    else:\n",
    "        ValueError(\n",
    "            'Cannot generate category mapping dictionary. Please check if training and inference datasets are compatible.')\n",
    "    cat_mapping_dict = dict(\n",
    "        (dataset_mapping_dict[k], v) for k, v in cat_mapping_dict.items())\n",
    "\n",
    "# Build predictor\n",
    "model = build_model(cfg)\n",
    "\n",
    "DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "            \"/home/richard.tanai/cvpr2/pod_compare/data_backup/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_0/model_final.pth\", resume=False)\n",
    "\n",
    "#for debug purposes\n",
    "cfg.ACTIVE_LEARNING.START_N = 100 \n",
    "\n",
    "trainer = ActiveTrainer(cfg, model)\n",
    "#trainer.resume_or_load(resume=True)\n",
    "\n",
    "#predictor = build_predictor(cfg, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rising-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/24 12:33:18 d2.data.datasets.coco]: \u001b[0mLoaded 10000 images in COCO format from /public-dataset/BDD/bdd100k/labels/val_coco_format.json\n",
      "\u001b[32m[02/24 12:33:19 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    car     | 102506       |    bus     | 1597         |   truck    | 4245         |\n",
      "|   person   | 13262        |   rider    | 649          |    bike    | 1007         |\n",
      "|   motor    | 452          |            |              |            |              |\n",
      "|   total    | 123718       |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[02/24 12:33:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/24 12:33:19 d2.data.common]: \u001b[0mSerializing 10000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/24 12:33:19 d2.data.common]: \u001b[0mSerialized dataset takes 9.03 MiB\n",
      "performing train step 1\n",
      "\u001b[32m[02/24 12:33:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/24 12:33:43 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_1000/model_final.pth\n",
      "\u001b[32m[02/24 12:33:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 49  total_loss: 0.4013  loss_cls: 0.1315  loss_box_reg: 0.2638  time: 0.4322  data_time: 0.0097  lr: 0.00012488  max_mem: 8404M\n",
      "\u001b[32m[02/24 12:33:43 d2.engine.hooks]: \u001b[0mOverall training speed: 48 iterations in 0:00:20 (0.4322 s / it)\n",
      "\u001b[32m[02/24 12:33:43 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:21 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# 10000 is already started in the init\n",
    "# epoch is 20, just an arbitrary number lol\n",
    "\n",
    "predictor = build_predictor(cfg, model)\n",
    "\n",
    "test_data_loader = build_detection_test_loader(\n",
    "    cfg, dataset_name=args.test_dataset)\n",
    "train_step = 1\n",
    "label_per_step = 100\n",
    "while(1):\n",
    "    print(f\"performing train step {train_step}\")\n",
    "    trainer.train()\n",
    "    torch.save(model.state_dict(), f\"outputs/checkpoint_step{train_step}.pth\")\n",
    "    if len(trainer.dataset) >= label_per_step:\n",
    "        trainer.dataset.label_randomly(label_per_step)\n",
    "    elif len(trainer.dataset) > 0:\n",
    "        trainer.datasaet.label_randomly(len(trainer.dataset))\n",
    "    else:\n",
    "        break\n",
    "    trainer.rebuild_trainer()\n",
    "    train_step += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "military-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.dataset.pool)\n",
    "trainer.dataset.label_randomly(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blocked-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': '/public-dataset/BDD/bdd100k/images/100k/train/0309a59f-1c34bcb8.jpg',\n",
       " 'height': 720,\n",
       " 'width': 1280,\n",
       " 'image_id': 1133,\n",
       " 'annotations': [{'iscrowd': 0,\n",
       "   'bbox': [385.697227, 394.094862, 54.194289000000026, 85.66194000000002],\n",
       "   'category_id': 2,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [446.884326, 409.828688, 124.12240299999996, 110.13677799999999],\n",
       "   'category_id': 2,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [293.042476, 406.332281, 43.70507199999997, 47.20147799999995],\n",
       "   'category_id': 2,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [590.236959, 460.52657, 96.15115700000001, 61.18709899999999],\n",
       "   'category_id': 1,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [424.15769, 448.289148, 13.98562099999998, 19.230232],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [431.150501, 451.785555, 17.482028999999955, 15.733825000000024],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [481.848384, 460.52657, 134.61162000000002, 99.647561],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [516.812441, 500.735234, 180.064891, 141.60443099999998],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [618.208206, 441.296337, 660.8206769999999, 276.216051],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [34.308454, 388.850251, 505.23062300000004, 328.662137],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [279.056853, 422.066107, 17.48203000000001, 15.733826000000022],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [224.862565, 422.066107, 83.913737, 33.215854000000036],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [135.70422, 401.087673, 31.467652000000015, 41.956867999999986],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [98.99196, 397.591266, 43.705071000000004, 43.705070999999975],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [37.804861, 392.346658, 73.42452, 48.949679],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>},\n",
       "  {'iscrowd': 0,\n",
       "   'bbox': [0, 390.598455, 32.225365, 54.194289000000026],\n",
       "   'category_id': 0,\n",
       "   'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "complimentary-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n"
     ]
    }
   ],
   "source": [
    "print(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco has 80000 images\n",
    "# the max iter is 90000 and batchsize of 4, making it about 4.5epochs\n",
    "# for this study 4 epochs will be used instead\n",
    "# no weights refresh will be used\n",
    "# hooks are now rebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pointed-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction outputs\n",
    "# in what order are the outputs arranged, they are arranged by the max clas pred score\n",
    "\n",
    "\n",
    "# to do\n",
    "# change test dataloader to pool dataloader\n",
    "# use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valid-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.build import DatasetMapper, get_detection_dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confused-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/23 20:14:16 d2.data.datasets.coco]: \u001b[0mLoaded 10000 images in COCO format from /public-dataset/BDD/bdd100k/labels/val_coco_format.json\n"
     ]
    }
   ],
   "source": [
    "dataset = get_detection_dataset_dicts([args.test_dataset],filter_empty=False, proposal_files=[\n",
    "            cfg.DATASETS.PROPOSAL_FILES_TEST[list(cfg.DATASETS.TEST).index(dataset_name)]\n",
    "        ]\n",
    "        if cfg.MODEL.LOAD_PROPOSALS\n",
    "        else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "perfect-airplane",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-11307c779544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "dataset([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_list = []\n",
    "cls_score_list = []\n",
    "box_score_list = []\n",
    "\n",
    "\n",
    "if not args.eval_only:\n",
    "    with torch.no_grad():\n",
    "        with tqdm.tqdm(total=len(test_data_loader)) as pbar:\n",
    "            for idx, input_im in enumerate(test_data_loader):\n",
    "                #print(input_im.size)\n",
    "                outputs = predictor(input_im)\n",
    "                final_output_list.extend(\n",
    "                    instances_to_json(\n",
    "                        outputs,\n",
    "                        input_im[0]['image_id'],\n",
    "                        cat_mapping_dict))\n",
    "                results = outputs\n",
    "                \n",
    "                cls_preds = results.pred_cls_probs.cpu().numpy()\n",
    "                predicted_boxes = results.pred_boxes.tensor.cpu().numpy()\n",
    "                predicted_covar_mats = results.pred_boxes_covariance.cpu().numpy()\n",
    "                \n",
    "                box_score = np.array([mat.diagonal().prod() for mat in predicted_covar_mats]).mean()\n",
    "                #mean of the max confidence\n",
    "                cls_score = cls_preds.max(axis=1).mean()\n",
    "                #change cls_score to entropy next time\n",
    "                box_score_list.append(box_score)\n",
    "                cls_score_list.append(cls_score)\n",
    "                \n",
    "                pbar.update(1)\n",
    "                \n",
    "                \n",
    "cls_score_rank = np.array(cls_score_list).argsort().argsort()\n",
    "box_score_rank = (-np.array(box_score_list)).argsort().argsort()\n",
    "total_sort = np.argsort(cls_score_rank + box_score_rank)\n",
    "idx_to_label = total_sort[:10000].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort from most uncertain to least uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "organizational-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_score_rank = np.array(cls_score_list).argsort().argsort()\n",
    "box_score_rank = (-np.array(box_score_list)).argsort().argsort()\n",
    "total_sort = np.argsort(cls_score_rank + box_score_rank)\n",
    "idx_to_label = total_sort[:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fundamental-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cls_entropy(cls_preds, merge=\"mean\"):\n",
    "    \n",
    "    assert len(cls_preds.shape) == 2\n",
    "    \n",
    "    ent = np.array([])\n",
    "    for det_preds in cls_preds:\n",
    "        ent = np.append(ent, (-det_preds*np.log(det_preds)).sum())\n",
    "    \n",
    "    print(ent)\n",
    "    if merge == \"mean\":\n",
    "        \n",
    "        return ent.mean()\n",
    "    \n",
    "    elif merge == \"max\":\n",
    "        return ent.max()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid detection merge mode for entropy {}.'.format(merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smaller-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cls_max_conf(cls_preds, merge=\"mean\"):\n",
    "    assert len(cls_preds.shape) == 2\n",
    "    \n",
    "    if merge == \"mean\":\n",
    "        \n",
    "        return cls_preds.max(axis=1).mean()\n",
    "    \n",
    "    elif merge == \"max\":\n",
    "        return cls_preds.max(axis=1).max()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid detection merge mode for max_conf {}.'.format(merge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "occasional-prayer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing train step 1\n",
      "\u001b[32m[02/07 10:54:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[02/07 10:54:36 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_1000/model_final.pth\n",
      "\u001b[32m[02/07 10:54:36 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 49  total_loss: 0.4013  loss_cls: 0.1315  loss_box_reg: 0.2638  time: 0.4352  data_time: 0.0095  lr: 0.00012488  max_mem: 8404M\n",
      "\u001b[32m[02/07 10:54:36 d2.engine.hooks]: \u001b[0mOverall training speed: 48 iterations in 0:00:20 (0.4352 s / it)\n",
      "\u001b[32m[02/07 10:54:36 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:21 (0:00:00 on hooks)\n",
      "\u001b[32m[02/07 10:54:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 202/69305 [01:13<6:58:53,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of the pool is 69305\n"
     ]
    }
   ],
   "source": [
    "#loop using entropy\n",
    "train_step = 1\n",
    "label_per_step = 100\n",
    "# cfg.ACTIVE_LEARNING.OUT_DIR\n",
    "out_dir = \"outputs_v1_10k\"\n",
    "\n",
    "# entropy or max_conf\n",
    "\n",
    "# cfg.ACTIVE_LEARNING.DET_CLS_SCORE\n",
    "det_cls_score = \"entropy\"\n",
    "\n",
    "#cfg.ACTIVE_LEARNING.DET_CLS_MERGE_MODE\n",
    "det_cls_merge_mode = \"mean\"\n",
    "\n",
    "# cls score and box score weighted sum factor, 1 is full cls_score\n",
    "# cfg.ACTIVE_LEARNING.W_CLS_SCORE\n",
    "w_cls_score = 1\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    print(f\"performing train step {train_step}\")\n",
    "    trainer.train()\n",
    "    torch.save(model.state_dict(), f\"{out_dir}/checkpoint_step{train_step}.pth\")\n",
    "\n",
    "    pool_loader = trainer.build_pool_dataloader()\n",
    "\n",
    "    final_output_list = []\n",
    "    cls_score_list = []\n",
    "    box_score_list = []\n",
    "\n",
    "    predictor = build_predictor(cfg, model)\n",
    "\n",
    "    if not args.eval_only:\n",
    "        with torch.no_grad():\n",
    "            with tqdm.tqdm(total=len(pool_loader)) as pbar:\n",
    "                for idx, input_im in enumerate(pool_loader):\n",
    "                    #print(input_im.size)\n",
    "                    outputs = predictor(input_im)\n",
    "                    final_output_list.extend(\n",
    "                        instances_to_json(\n",
    "                            outputs,\n",
    "                            input_im[0]['image_id'],\n",
    "                            cat_mapping_dict))\n",
    "                    results = outputs\n",
    "\n",
    "                    cls_preds = results.pred_cls_probs.cpu().numpy()\n",
    "                    predicted_boxes = results.pred_boxes.tensor.cpu().numpy()\n",
    "                    predicted_covar_mats = results.pred_boxes_covariance.cpu().numpy()\n",
    "\n",
    "                    box_score = np.array([mat.diagonal().prod() for mat in predicted_covar_mats]).mean()\n",
    "                    #mean of the max confidence pre detection\n",
    "                    if det_cls_score == \"entropy\":\n",
    "                        cls_score = compute_cls_entropy(cls_preds, det_cls_merge_mode) #entropy, mean default\n",
    "                    elif det_cls_score == \"max_conf\":\n",
    "                        cls_score = compute_cls_max_conf(cls_preds, det_cls_merge_mode)\n",
    "                    else:\n",
    "                        raise ValueError('Invalid det_cls_score {}.'.format(det_cls_score))\n",
    "                        \n",
    "                    box_score_list.append(box_score)\n",
    "                    cls_score_list.append(cls_score)\n",
    "\n",
    "                    pbar.update(1)\n",
    "                    if idx > label_per_step*2:\n",
    "                        print(f\"the length of the pool is {len(pool_loader)}\")\n",
    "                        break\n",
    "\n",
    "\n",
    "    cls_score_rank = np.array(cls_score_list).argsort().argsort()\n",
    "    box_score_rank = (-np.array(box_score_list)).argsort().argsort()\n",
    "\n",
    "    #possible weighted fusion can be added here\n",
    "    total_sort = np.argsort((w_cls_score)*cls_score_rank + (1-w_cls_score)*box_score_rank)\n",
    "    \n",
    "\n",
    "    if len(trainer.dataset.pool) >= label_per_step:\n",
    "        idx_to_label = total_sort[:label_per_step].tolist()\n",
    "        trainer.dataset.label(idx_to_label)\n",
    "        break\n",
    "    elif len(trainer.dataset.pool) > 0:\n",
    "        trainer.dataset.label_randomly(len(trainer.dataset.pool))\n",
    "    else:\n",
    "        break\n",
    "    trainer.rebuild_trainer()\n",
    "    train_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "embedded-outside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6735816  0.65458161 0.57290536 0.6810838  1.10173106 1.17634439\n",
      " 1.14614856 0.79682165 0.89564419 0.97529751 1.5059154  1.09316909\n",
      " 1.17639792 1.2976594  1.07864618 1.14987123 1.50417042 1.05135262\n",
      " 1.09704983 1.04031229 0.98953509 0.98289454 1.2418803  0.83059418\n",
      " 0.94581699 0.97859418 1.22000003 1.13844299 1.32917404 1.27367914\n",
      " 1.0694921  1.26989162 0.89865428 0.91713995 0.8677687  1.13772607\n",
      " 0.81497902 1.30278134 0.93699443 1.28821516 1.08093369 1.39140105\n",
      " 1.48048925 0.87731302 1.29598498 0.68839628 0.88472193 1.38740277\n",
      " 0.83700693 0.83375919 1.34075356 0.88505739 0.73032075 0.90696609\n",
      " 1.0937072  0.97115868 0.7281034  0.66081011 0.99408495 0.6231001\n",
      " 0.61153191 1.05822253 0.91620499 0.69298375 0.70925486 1.12173009\n",
      " 1.09421694 0.92841303 0.87815624 0.79633689 0.91192293 0.75956959\n",
      " 0.83807367 0.80594772 0.60729116 0.70997304 0.90303493 0.71641445\n",
      " 0.62639457 0.77782333 0.61238778 0.64644831 0.67987573 1.02581084\n",
      " 0.69630688 1.05626202 0.58497572 0.58348227 0.70365292 0.77111793\n",
      " 0.54548949 0.72638714 0.79160118 0.7841512  0.62385339 0.5981639\n",
      " 0.74636239 0.60456049 0.60113138 0.56522506]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.922051522731781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cls_entropy(cls_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ancient-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6347876214064084,\n",
       " 0.868465895652771,\n",
       " 0.7172797167301178,\n",
       " 0.6561238023638726,\n",
       " 0.5725444634445012,\n",
       " 0.7031967601180077,\n",
       " 0.6380870440602302,\n",
       " 0.6820839682350988,\n",
       " 0.8562709707574746,\n",
       " 0.641229946570224,\n",
       " 0.6777238786220551,\n",
       " 0.815227597951889,\n",
       " 0.9003307051518384,\n",
       " 0.6449304457570686,\n",
       " 0.6527539189311041,\n",
       " 0.6444879284460251,\n",
       " 0.827795016169548,\n",
       " 0.5849748653369945,\n",
       " 0.7724103718996048,\n",
       " 0.7825853398442268,\n",
       " 0.7859344157305631,\n",
       " 0.9280733913183212,\n",
       " 0.7855429524725134,\n",
       " 0.9066429895162582,\n",
       " 0.7241702654957771,\n",
       " 0.7221918654441833,\n",
       " 0.9411766767501831,\n",
       " 0.7827674907942613,\n",
       " 0.81192287504673,\n",
       " 0.6476578989624977,\n",
       " 0.8705913777254066,\n",
       " 0.7119450056552887,\n",
       " 0.9234286105632782,\n",
       " 0.8602607727050782,\n",
       " 0.7171079965605252,\n",
       " 0.8297125205397606,\n",
       " 0.6850364674863062,\n",
       " 0.7304124458767902,\n",
       " 0.8570292297005654,\n",
       " 0.7242111459374427,\n",
       " 0.7089610090851783,\n",
       " 0.7781022521853447,\n",
       " 0.8282436151057482,\n",
       " 0.8120404353737831,\n",
       " 1.026125004887581,\n",
       " 0.6144294988135902,\n",
       " 0.7408296513557434,\n",
       " 0.7444659778475762,\n",
       " 0.6393050214648247,\n",
       " 0.6678960394859313,\n",
       " 0.6960433211922645,\n",
       " 0.7453207540512085,\n",
       " 0.7095564490556717,\n",
       " 0.8620667429765065,\n",
       " 0.8098473253846169,\n",
       " 0.7241292319127491,\n",
       " 0.7154480633379399,\n",
       " 0.6234948720250811,\n",
       " 0.6258889509571923,\n",
       " 0.7624622899752397,\n",
       " 0.9546206903457641,\n",
       " 0.7851351943612098,\n",
       " 0.8538076660037041,\n",
       " 0.8546913203597069,\n",
       " 0.6664020035948072,\n",
       " 0.6608097362212646,\n",
       " 0.5486864490168435,\n",
       " 0.8491448800814779,\n",
       " 0.8733639253510369,\n",
       " 0.7426631283760071,\n",
       " 0.6831128753952145,\n",
       " 0.6968757010794975,\n",
       " 0.6989195397202398,\n",
       " 0.8961425012350083,\n",
       " 0.6392838609218597,\n",
       " 0.7380839319064699,\n",
       " 0.9267502564191819,\n",
       " 0.8540071672201157,\n",
       " 0.6998757033408443,\n",
       " 0.686804826259613,\n",
       " 0.6885673307320651,\n",
       " 0.7352295160293579,\n",
       " 0.7109415731098079,\n",
       " 0.7700800743699073,\n",
       " 0.6352381435307589,\n",
       " 0.6785711802617468,\n",
       " 0.6277306067943573,\n",
       " 0.6829532417986128,\n",
       " 0.5916784682224706,\n",
       " 0.8429955005645752,\n",
       " 0.6240262076797256,\n",
       " 0.6560506140118214,\n",
       " 0.6759244780386647,\n",
       " 0.8145788468420505,\n",
       " 1.0022591158747673,\n",
       " 0.729259861111641,\n",
       " 0.811260418759452,\n",
       " 0.7240300819277763,\n",
       " 0.6615879493951797,\n",
       " 0.6336041662096977,\n",
       " 0.6681835375105342,\n",
       " 0.7546120798587799,\n",
       " 0.6755058373977889,\n",
       " 0.7020378541655656,\n",
       " 0.7565207815170288,\n",
       " 0.7154418021440506,\n",
       " 0.6756818070239627,\n",
       " 0.6043819592644771,\n",
       " 0.6453845162450531,\n",
       " 0.7324962595105171,\n",
       " 0.6065257728884095,\n",
       " 0.62013407561877,\n",
       " 0.8003656046187624,\n",
       " 0.7336337915909144,\n",
       " 0.7061631464958191,\n",
       " 0.6445381933450699,\n",
       " 0.9455029666423798,\n",
       " 0.6421291208267212,\n",
       " 0.7969125998020172,\n",
       " 0.9048069445710433,\n",
       " 0.6718438323806314,\n",
       " 0.9667961221933364,\n",
       " 0.6012983798980713,\n",
       " 0.6272116579035277,\n",
       " 0.7867631170153618,\n",
       " 0.9930433053293346,\n",
       " 0.7722822644953,\n",
       " 0.7218144151611604,\n",
       " 0.6850879060238907,\n",
       " 0.5666847382154729,\n",
       " 0.9853602004051208,\n",
       " 0.8941352221369744,\n",
       " 0.882297505736351,\n",
       " 0.7171379526456197,\n",
       " 0.670725358121189,\n",
       " 0.6002919706629544,\n",
       " 0.6532700266061204,\n",
       " 0.8075878578424454,\n",
       " 0.8343760699410981,\n",
       " 0.9763528043031693,\n",
       " 0.6623918052469746,\n",
       " 0.8085815411806107,\n",
       " 0.6656356021052315,\n",
       " 0.6472085964679718,\n",
       " 0.8301932698488236,\n",
       " 0.9009596595168113,\n",
       " 0.9381439498066902,\n",
       " 0.7761624348469269,\n",
       " 0.8510164941058439,\n",
       " 0.7043678688375573,\n",
       " 0.8403554254770279,\n",
       " 0.5219729897379876,\n",
       " 0.714985224531918,\n",
       " 0.6629405185580254,\n",
       " 0.7006730794122344,\n",
       " 0.9168956339359283,\n",
       " 0.6414549560064361,\n",
       " 0.7763431990387464,\n",
       " 0.8162017166614532,\n",
       " 0.7895329546928406,\n",
       " 0.7244534042218457,\n",
       " 0.841755808382244,\n",
       " 0.7182053335955445,\n",
       " 0.7122202545404435,\n",
       " 0.7288156045579363,\n",
       " 0.7121361470781267,\n",
       " 0.9825120341777801,\n",
       " 0.7577047566088234,\n",
       " 0.7695761636520425,\n",
       " 0.5812002724409103,\n",
       " 0.8521186205744743,\n",
       " 0.8832256576418877,\n",
       " 0.806755399107933,\n",
       " 0.7645972031354904,\n",
       " 0.7288809728622436,\n",
       " 0.677766984047955,\n",
       " 0.818995994190837,\n",
       " 0.7235160908102989,\n",
       " 0.9563329291867686,\n",
       " 0.9245820511789883,\n",
       " 0.7585822191644223,\n",
       " 0.8938168118698429,\n",
       " 0.8872581686866418,\n",
       " 0.8361698126792908,\n",
       " 0.835016080737114,\n",
       " 0.7708750143647194,\n",
       " 0.6167247426509858,\n",
       " 0.6340696657278452,\n",
       " 0.7906898415088653,\n",
       " 0.8928100270032883,\n",
       " 0.8929533210396766,\n",
       " 0.5855954066775311,\n",
       " 0.6944286680221557,\n",
       " 0.7169297102093697,\n",
       " 0.623640730381012,\n",
       " 0.6028047105888041,\n",
       " 0.7234323817491531,\n",
       " 0.7054518210887909,\n",
       " 0.7020977611871476,\n",
       " 0.7488389942381117,\n",
       " 0.8271110960841179,\n",
       " 0.922051522731781]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "combined-advance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1,2,3],[1,2,3]])\n",
    "b.mean().max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accredited-martial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24, 169,  89,  41,   3,  73,  26,  58, 165,  29,  55, 145, 180,\n",
       "        34,  38,  32, 149,   5, 123, 127, 131, 189, 130, 183,  97,  92,\n",
       "       191, 128, 142,  37, 170,  80, 186, 167,  87, 151,  61, 103, 166,\n",
       "        98,  77, 126, 150, 143, 201,  13, 108, 110,  28,  48,  66, 111,\n",
       "        78, 168, 140,  96,  85,  16,  19, 117, 193, 129, 162, 164,  47,\n",
       "        42,   1, 159, 171, 109,  60,  67,  68, 179,  27, 107, 188, 163,\n",
       "        69,  63,  64, 106,  79, 120,  25,  57,  21,  59,   7, 158,  18,\n",
       "        40,  54, 144, 200, 102, 141,  95,  43,  22,  49, 113,  52,  71,\n",
       "       114,  84,  53,  11,  35, 104,  12,  15, 136, 105,  76,  33, 192,\n",
       "        31, 135, 182,  51, 195,   9,  20, 132, 199, 122,  91,  62,   2,\n",
       "       198, 178, 172,  88,  50,   8,  39, 138, 153, 196,  44, 139,  46,\n",
       "        36, 152, 181, 190, 124, 160,  74, 156,   0,  83,  45,  70, 184,\n",
       "        30, 125, 146, 133,  99, 157,  90,  82, 100,  81, 197, 115, 119,\n",
       "         4, 161, 173, 137, 118, 101,  56, 147,  94, 194, 187, 116, 177,\n",
       "       174, 155, 154, 121,  14,  23, 134, 175, 176,   6,  65,  86,  17,\n",
       "        10,  93,  75,  72, 112, 148, 185])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_score_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pregnant-glance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105,  68,  39,  59,   6,  87,  33,  53, 168,  56,   5, 179, 145,\n",
       "        95,  54,  19, 146,  52, 159,  40,  82, 177, 101,  80,  45, 141,\n",
       "       171, 199,  77,  10, 129, 139, 152, 161, 181, 111,  51, 138, 142,\n",
       "        96,  48, 114, 133, 121, 119,  61, 167, 110,   3,  44, 109,  12,\n",
       "        57, 150, 156, 112, 127, 106,  16, 176, 157,  60,  49,  65,  73,\n",
       "        22,  30, 174, 184, 166,  47, 140, 195,  89,  18, 125, 189, 128,\n",
       "        74,  24, 194,  76, 148, 130, 134,  62,   8,  32,   0,  78,  23,\n",
       "       163,  34,  14, 196,  98, 123,  25,  71,  31, 104,  93, 155, 175,\n",
       "        94,  63,  50,  66,  20,  79,   7,  58,   9, 115,  46,  36, 186,\n",
       "        91,  38, 178,  90, 185,  67, 107,  75, 188, 201, 172,  85,   1,\n",
       "       149, 117, 126, 192, 160,  81,  43, 124, 198, 103,  35,  13, 113,\n",
       "        26,  55, 122, 180, 197, 143,  84,  83,   2, 191,  15, 118, 187,\n",
       "        92, 100, 183, 108, 151, 136, 165,  64,  97, 169, 131, 158, 147,\n",
       "         4,  70, 154, 153,  99,  37, 173, 164,  86, 190, 162, 200, 120,\n",
       "       193,  88, 137, 135,  69, 116, 102, 144, 132,  11,  17,  21,  29,\n",
       "        28,  41,  42,  27, 170,  72, 182])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w_cls_score)*cls_score_rank + (1-w_cls_score)*box_score_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "internal-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_diag(x):\n",
    "    print(x)\n",
    "    return x.diagonal().prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "colored-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1481842400000.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([mat.diagonal().prod() for mat in predicted_covar_mats]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_over_axes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlimited-rolling",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contained-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inference Script\n",
    "\"\"\"\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "# Detectron imports|\n",
    "from detectron2.engine import launch\n",
    "from detectron2.data.dataset_mapper import DatasetMapper\n",
    "from detectron2.data import *\n",
    "from detectron2.data.build import trivial_batch_collator\n",
    "from detectron2.data.samplers.distributed_sampler import InferenceSampler\n",
    "\n",
    "# Project imports\n",
    "import core.datasets.metadata as metadata\n",
    "\n",
    "from core.setup import setup_config, setup_arg_parser\n",
    "from offline_evaluation import compute_average_precision, compute_probabilistic_metrics, compute_calibration_errors\n",
    "from probabilistic_inference.probabilistic_inference import build_predictor\n",
    "from probabilistic_inference.inference_utils import instances_to_json\n",
    "\n",
    "from baal.active import FileDataset, ActiveLearningDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "willing-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command Line Args: Namespace(config_file='/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml', dataset_dir='/public-dataset/BDD/bdd100k', dist_url='tcp://127.0.0.1:50162', eval_only=False, inference_config='/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml', iou_correct=0.7, iou_min=0.1, machine_rank=0, min_allowed_score=0.0, num_gpus=1, num_machines=1, opts=[], random_seed=0, resume=False, test_dataset='bdd_val')\n"
     ]
    }
   ],
   "source": [
    "##setup inference args, this also contains all the training args\n",
    "arg_parser = setup_arg_parser()\n",
    "args = arg_parser.parse_args(\"\")\n",
    "# Support single gpu inference only.\n",
    "args.num_gpus = 1\n",
    "args.dataset_dir = '/public-dataset/BDD/bdd100k'\n",
    "args.test_dataset = 'bdd_val'\n",
    "args.config_file = '/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml'\n",
    "args.inference_config = '/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml'\n",
    "print(\"Command Line Args:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lonely-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "global result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "massive-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method inside the build detection train loader that loads from config\n",
    "def load_dataset_and_mapper_from_config(cfg, dataset_name='bdd_val', mapper=None):\n",
    "    \"\"\"\n",
    "    Uses the given `dataset_name` argument (instead of the names in cfg), because the\n",
    "    standard practice is to evaluate each test set individually (not combining them).\n",
    "    \"\"\"\n",
    "    dataset = get_detection_dataset_dicts(\n",
    "        [dataset_name],\n",
    "        filter_empty=False,\n",
    "        proposal_files=[\n",
    "            cfg.DATASETS.PROPOSAL_FILES_TEST[list(cfg.DATASETS.TEST).index(dataset_name)]\n",
    "        ]\n",
    "        if cfg.MODEL.LOAD_PROPOSALS\n",
    "        else None,\n",
    "    )\n",
    "    # use active learning dataset wrapper\n",
    "    if mapper is None:\n",
    "        mapper = DatasetMapper(cfg, False)\n",
    "        \n",
    "    return dataset, mapper\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trying-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_from_config(cfg, dataset, mapper):\n",
    "    if isinstance(dataset, list):\n",
    "        dataset = DatasetFromList(dataset, copy=False)\n",
    "    if mapper is not None:\n",
    "        dataset = MapDataset(dataset, mapper)\n",
    "    sampler = InferenceSampler(len(dataset))\n",
    "    # Always use 1 image per worker during inference since this is the\n",
    "    # standard when reporting inference time in papers.\n",
    "    batch_sampler = torch.utils.data.sampler.BatchSampler(sampler, 1, drop_last=False)\n",
    "    num_worker = 4\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        num_workers=num_worker,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=trivial_batch_collator,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "scenic-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method inside the build detection train loader that loads from config\n",
    "def test_loader_from_config(cfg, dataset_name='bdd_val', mapper=None):\n",
    "    \"\"\"\n",
    "    Uses the given `dataset_name` argument (instead of the names in cfg), because the\n",
    "    standard practice is to evaluate each test set individually (not combining them).\n",
    "    \"\"\"\n",
    "    dataset = get_detection_dataset_dicts(\n",
    "        [dataset_name],\n",
    "        filter_empty=False,\n",
    "        proposal_files=[\n",
    "            cfg.DATASETS.PROPOSAL_FILES_TEST[list(cfg.DATASETS.TEST).index(dataset_name)]\n",
    "        ]\n",
    "        if cfg.MODEL.LOAD_PROPOSALS\n",
    "        else None,\n",
    "    )\n",
    "    # use active learning dataset wrapper\n",
    "    dataset = ActiveLearningDataset(dataset)\n",
    "    dataset.label_randomly(100)\n",
    "    if mapper is None:\n",
    "        mapper = DatasetMapper(cfg, False)\n",
    "    \n",
    "    if isinstance(dataset, list):\n",
    "        dataset = DatasetFromList(dataset, copy=False)\n",
    "    if mapper is not None:\n",
    "        dataset = MapDataset(dataset, mapper)\n",
    "    sampler = InferenceSampler(len(dataset))\n",
    "    # Always use 1 image per worker during inference since this is the\n",
    "    # standard when reporting inference time in papers.\n",
    "    batch_sampler = torch.utils.data.sampler.BatchSampler(sampler, 1, drop_last=False)\n",
    "    num_worker = 4\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        num_workers=num_worker,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=trivial_batch_collator,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authentic-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/05 17:25:53 fvcore.common.config]: \u001b[0mLoading config /home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/../../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/05 17:25:53 d2.config.compat]: \u001b[0mConfig '/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "\u001b[32m[02/05 17:25:53 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[02/05 17:25:54 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ----------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]\n",
      "numpy                   1.19.5\n",
      "detectron2              0.3 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.2\n",
      "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.7.1 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  8.1.0\n",
      "torchvision             0.8.2 @/opt/anaconda3/envs/pod/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\n",
      "fvcore                  0.1.2.post20210115\n",
      "cv2                     4.5.1\n",
      "----------------------  ----------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "\u001b[32m[02/05 17:25:54 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml', dataset_dir='/public-dataset/BDD/bdd100k', dist_url='tcp://127.0.0.1:50162', eval_only=False, inference_config='/home/richard.tanai/cvpr2/pod_compare/src/configs/Inference/bayes_od_mc_dropout.yaml', iou_correct=0.7, iou_min=0.1, machine_rank=0, min_allowed_score=0.0, num_gpus=1, num_machines=1, opts=[], random_seed=0, resume=False, test_dataset='bdd_val')\n",
      "\u001b[32m[02/05 17:25:54 detectron2]: \u001b[0mContents of args.config_file=/home/richard.tanai/cvpr2/pod_compare/src/configs/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout.yaml:\n",
      "_BASE_: \"Base-BDD-RetinaNet.yaml\"\n",
      "\n",
      "MODEL:\n",
      "    PROBABILISTIC_MODELING:\n",
      "        DROPOUT_RATE: 0.2 # 0.0 for no dropout\n",
      "\n",
      "        # One of the following Loss types: loss_attenuation'.\n",
      "        CLS_VAR_LOSS:\n",
      "            NAME: 'loss_attenuation'\n",
      "            NUM_SAMPLES: 10\n",
      "\n",
      "        # One of the following Loss types: 'none' or 'negative_log_likelihood', 'second_moment_matching', 'energy_loss'.\n",
      "        BBOX_COV_LOSS:\n",
      "            NAME: 'negative_log_likelihood'\n",
      "            COVARIANCE_TYPE: 'diagonal' # One of the following: 'full', 'diagonal' # Settings for dropout\n",
      "\u001b[32m[02/05 17:25:54 detectron2]: \u001b[0mRunning with full config:\n",
      "ACTIVE_LEARNING:\n",
      "  EPOCH: 2\n",
      "  START_N: 10000\n",
      "  STEP_N: 10000\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 8\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('bdd_val',)\n",
      "  TRAIN: ('bdd_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (720,)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: ProbabilisticRetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROBABILISTIC_MODELING:\n",
      "    ANNEALING_STEP: 0\n",
      "    BBOX_COV_LOSS:\n",
      "      COVARIANCE_TYPE: diagonal\n",
      "      NAME: negative_log_likelihood\n",
      "      NUM_SAMPLES: 1000\n",
      "    CLS_VAR_LOSS:\n",
      "      NAME: loss_attenuation\n",
      "      NUM_SAMPLES: 10\n",
      "    DROPOUT_RATE: 0.2\n",
      "    MC_DROPOUT:\n",
      "      \n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 7\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    DROPOUT_RATE: 0.2\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
      "OUTPUT_DIR: /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_0\n",
      "PROBABILISTIC_INFERENCE:\n",
      "  AFFINITY_THRESHOLD: 0.9\n",
      "  BAYES_OD:\n",
      "    BOX_MERGE_MODE: bayesian_inference\n",
      "    CLS_MERGE_MODE: max_score\n",
      "    DIRCH_PRIOR: uniform\n",
      "  ENSEMBLES:\n",
      "    BOX_MERGE_MODE: pre_nms\n",
      "    RANDOM_SEED_NUMS: [0, 1000, 2000, 3000, 4000]\n",
      "  ENSEMBLES_DROPOUT:\n",
      "    BOX_MERGE_MODE: pre_nms\n",
      "  INFERENCE_MODE: bayes_od\n",
      "  MC_DROPOUT:\n",
      "    ENABLE: True\n",
      "    NUM_RUNS: 10\n",
      "SEED: 0\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.0025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 30000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 4\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 90000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 17:25:54 detectron2]: \u001b[0mFull config saved to /home/richard.tanai/cvpr2/pod_compare/data/BDD-Detection/retinanet/retinanet_R_50_FPN_1x_reg_cls_var_dropout/random_seed_0/config.yaml\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'bdd_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dee47d654e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run this once per session only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_testing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cvpr2/pod_compare/src/core/setup.py\u001b[0m in \u001b[0;36msetup_config\u001b[0;34m(args, random_seed, is_testing)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Setup datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0msetup_all_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cvpr2/pod_compare/src/core/datasets/setup_datasets.py\u001b[0m in \u001b[0;36msetup_all_datasets\u001b[0;34m(dataset_dir)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msetup_bdd_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0msetup_kitti_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msetup_lyft_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cvpr2/pod_compare/src/core/datasets/setup_datasets.py\u001b[0m in \u001b[0;36msetup_bdd_dataset\u001b[0;34m(dataset_dir)\u001b[0m\n\u001b[1;32m     34\u001b[0m         dataset_dir, 'labels', 'val_coco_format.json')\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     register_coco_instances(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;34m\"bdd_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pod/lib/python3.8/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pod/lib/python3.8/site-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is already registered!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'bdd_train' is already registered!"
     ]
    }
   ],
   "source": [
    "# run this once per session only\n",
    "cfg = setup_config(args, random_seed=args.random_seed, is_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cutting-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/05 17:25:57 d2.data.datasets.coco]: \u001b[0mLoaded 10000 images in COCO format from /public-dataset/BDD/bdd100k/labels/val_coco_format.json\n",
      "\u001b[32m[02/05 17:25:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot perform reduction function max on tensor with no elements because the operation does not have an identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-433b44309fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_im\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m#print(input_im.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 final_output_list.extend(\n",
      "\u001b[0;32m~/cvpr2/pod_compare/src/probabilistic_inference/probabilistic_inference.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_im)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_processing_ensembles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bayes_od'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_processing_bayes_od\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m~/cvpr2/pod_compare/src/probabilistic_inference/probabilistic_inference.py\u001b[0m in \u001b[0;36mpost_processing_bayes_od\u001b[0;34m(self, input_im)\u001b[0m\n\u001b[1;32m    583\u001b[0m             center_binary_score, center_cat_idx = torch.max(\n\u001b[1;32m    584\u001b[0m                 predicted_prob_vectors_center, 0)\n\u001b[0;32m--> 585\u001b[0;31m             cluster_binary_scores, cat_idx = cluster_categorical_params.max(\n\u001b[0m\u001b[1;32m    586\u001b[0m                 1)\n\u001b[1;32m    587\u001b[0m             \u001b[0mclass_similarity_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcenter_cat_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot perform reduction function max on tensor with no elements because the operation does not have an identity"
     ]
    }
   ],
   "source": [
    "#cfg = setup_config(args, random_seed=args.random_seed, is_testing=True)\n",
    "\n",
    "# Make sure only 1 data point is processed at a time. This simulates\n",
    "# deployment.\n",
    "cfg.defrost()\n",
    "cfg.DATALOADER.NUM_WORKERS = 32\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "\n",
    "cfg.MODEL.DEVICE = device.type\n",
    "\n",
    "# Set up number of cpu threads\n",
    "torch.set_num_threads(cfg.DATALOADER.NUM_WORKERS)\n",
    "\n",
    "# Create inference output directory and copy inference config file to keep\n",
    "# track of experimental settings\n",
    "inference_output_dir = os.path.join(\n",
    "    cfg['OUTPUT_DIR'],\n",
    "    'inference',\n",
    "    args.test_dataset,\n",
    "    os.path.split(args.inference_config)[-1][:-5])\n",
    "os.makedirs(inference_output_dir, exist_ok=True)\n",
    "copyfile(args.inference_config, os.path.join(\n",
    "    inference_output_dir, os.path.split(args.inference_config)[-1]))\n",
    "\n",
    "# Get category mapping dictionary:\n",
    "train_thing_dataset_id_to_contiguous_id = MetadataCatalog.get(\n",
    "    cfg.DATASETS.TRAIN[0]).thing_dataset_id_to_contiguous_id\n",
    "test_thing_dataset_id_to_contiguous_id = MetadataCatalog.get(\n",
    "    args.test_dataset).thing_dataset_id_to_contiguous_id\n",
    "\n",
    "# If both dicts are equal or if we are performing out of distribution\n",
    "# detection, just flip the test dict.\n",
    "if (train_thing_dataset_id_to_contiguous_id == test_thing_dataset_id_to_contiguous_id) or (\n",
    "        cfg.DATASETS.TRAIN[0] == 'coco_not_in_voc_2017_train'):\n",
    "    cat_mapping_dict = dict(\n",
    "        (v, k) for k, v in test_thing_dataset_id_to_contiguous_id.items())\n",
    "else:\n",
    "    # If not equal, two situations: 1) BDD to KITTI and 2) COCO to PASCAL\n",
    "    cat_mapping_dict = dict(\n",
    "        (v, k) for k, v in test_thing_dataset_id_to_contiguous_id.items())\n",
    "    if 'voc' in args.test_dataset and 'coco' in cfg.DATASETS.TRAIN[0]:\n",
    "        dataset_mapping_dict = dict(\n",
    "            (v, k) for k, v in metadata.COCO_TO_VOC_CONTIGUOUS_ID.items())\n",
    "    elif 'kitti' in args.test_dataset and 'bdd' in cfg.DATASETS.TRAIN[0]:\n",
    "        dataset_mapping_dict = dict(\n",
    "            (v, k) for k, v in metadata.BDD_TO_KITTI_CONTIGUOUS_ID.items())\n",
    "    else:\n",
    "        ValueError(\n",
    "            'Cannot generate category mapping dictionary. Please check if training and inference datasets are compatible.')\n",
    "    cat_mapping_dict = dict(\n",
    "        (dataset_mapping_dict[k], v) for k, v in cat_mapping_dict.items())\n",
    "\n",
    "# Build predictor\n",
    "predictor = build_predictor(cfg)\n",
    "#orig_test_data_loader = build_detection_test_loader(cfg, dataset_name=args.test_dataset)\n",
    "#test_data_loader = test_loader_from_config(cfg, dataset_name='bdd_val', mapper=None)\n",
    "\n",
    "dataset, mapper = load_dataset_and_mapper_from_config(cfg, dataset_name='bdd_val', mapper=None)\n",
    "\n",
    "dataset = ActiveLearningDataset(dataset)\n",
    "dataset.label([1,2,3])\n",
    "#dataset.label_randomly(100)\n",
    "\n",
    "test_data_loader = dataloader_from_config(cfg, dataset, mapper)\n",
    "\n",
    "final_output_list = []\n",
    "if not args.eval_only:\n",
    "    with torch.no_grad():\n",
    "        with tqdm.tqdm(total=len(test_data_loader)) as pbar:\n",
    "            for idx, input_im in enumerate(test_data_loader):\n",
    "                #print(input_im.size)\n",
    "                outputs = predictor(input_im)\n",
    "\n",
    "                final_output_list.extend(\n",
    "                    instances_to_json(\n",
    "                        outputs,\n",
    "                        input_im[0]['image_id'],\n",
    "                        cat_mapping_dict))\n",
    "                pbar.update(1)\n",
    "                result_list = outputs\n",
    "                #break\n",
    "\n",
    "    with open(os.path.join(inference_output_dir, 'coco_instances_results.json'), 'w') as fp:\n",
    "        json.dump(final_output_list, fp, indent=4,\n",
    "                  separators=(',', ': '))\n",
    "\n",
    "compute_average_precision.main(args, cfg)\n",
    "#compute_probabilistic_metrics.main(args, cfg)\n",
    "#compute_calibration_errors.main(args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.label([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_data_loader = build_detection_test_loader(cfg, dataset_name=args.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list.pred_boxes_covariance.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_img = predictor.visualize_inference(input_im, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res_img)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_data_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = next(iter(test_data_loader))[0]['image']\n",
    "plt.imshow(raw_image)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-bibliography",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
